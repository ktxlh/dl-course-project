{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eDCRN9mZmo_",
        "outputId": "877fc866-b9a9-4577-f3db-646f15e3ee93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# %cd /content/drive/MyDrive/DLProject\n",
        "# !git clone https://github.com/mcgill-nlp/bias-bench.git\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/DLProject/bias-bench\n",
        "!python3 -m pip install -e ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNicCEHubmhp",
        "outputId": "440dd71c-34ff-4045-f790-89ddecb85ea3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/DLProject/bias-bench\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/drive/MyDrive/DLProject/bias-bench\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from bias-bench==0.1.0) (2.0.0+cu118)\n",
            "Collecting transformers==4.16.2\n",
            "  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy==1.7.3\n",
            "  Downloading scipy-1.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn==1.0.2\n",
            "  Downloading scikit_learn-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nltk==3.7.0\n",
            "  Downloading nltk-3.7-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m77.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets==1.18.3\n",
            "  Downloading datasets-1.18.3-py3-none-any.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.7/311.7 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate==0.5.1\n",
            "  Downloading accelerate-0.5.1-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.0/58.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.5.1->bias-bench==0.1.0) (1.22.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.5.1->bias-bench==0.1.0) (6.0)\n",
            "Collecting dill\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets==1.18.3->bias-bench==0.1.0) (23.1)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==1.18.3->bias-bench==0.1.0) (9.0.0)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets==1.18.3->bias-bench==0.1.0) (2.27.1)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub<1.0.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==1.18.3->bias-bench==0.1.0) (1.5.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets==1.18.3->bias-bench==0.1.0) (4.65.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from datasets==1.18.3->bias-bench==0.1.0) (2023.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk==3.7.0->bias-bench==0.1.0) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk==3.7.0->bias-bench==0.1.0) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk==3.7.0->bias-bench==0.1.0) (2022.10.31)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.0.2->bias-bench==0.1.0) (3.1.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.16.2->bias-bench==0.1.0) (3.12.0)\n",
            "Collecting tokenizers!=0.11.3,>=0.10.1\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m106.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->bias-bench==0.1.0) (4.5.0)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->bias-bench==0.1.0) (2.0.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->bias-bench==0.1.0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->bias-bench==0.1.0) (3.1.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->bias-bench==0.1.0) (1.11.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11.0->bias-bench==0.1.0) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11.0->bias-bench==0.1.0) (16.0.2)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==1.18.3->bias-bench==0.1.0) (2.0.12)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==1.18.3->bias-bench==0.1.0) (23.1.0)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==1.18.3->bias-bench==0.1.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==1.18.3->bias-bench==0.1.0) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==1.18.3->bias-bench==0.1.0) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->bias-bench==0.1.0) (2.1.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==1.18.3->bias-bench==0.1.0) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==1.18.3->bias-bench==0.1.0) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers==4.16.2->bias-bench==0.1.0) (1.16.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->bias-bench==0.1.0) (1.3.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895259 sha256=03b4ccef40527212dd850cef6f25c29264056ec668e4b20e30dfcc0ab8496bf5\n",
            "  Stored in directory: /root/.cache/pip/wheels/00/24/97/a2ea5324f36bc626e1ea0267f33db6aa80d157ee977e9e42fb\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, xxhash, scipy, sacremoses, nltk, multidict, frozenlist, dill, async-timeout, yarl, scikit-learn, multiprocess, huggingface-hub, aiosignal, transformers, aiohttp, datasets, accelerate, bias-bench\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.10.1\n",
            "    Uninstalling scipy-1.10.1:\n",
            "      Successfully uninstalled scipy-1.10.1\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.8.1\n",
            "    Uninstalling nltk-3.8.1:\n",
            "      Successfully uninstalled nltk-3.8.1\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "  Running setup.py develop for bias-bench\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "arviz 0.15.1 requires scipy>=1.8.0, but you have scipy 1.7.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.5.1 aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 bias-bench-0.1.0 datasets-1.18.3 dill-0.3.6 frozenlist-1.3.3 huggingface-hub-0.14.1 multidict-6.0.4 multiprocess-0.70.14 nltk-3.7 sacremoses-0.0.53 scikit-learn-1.0.2 scipy-1.7.3 tokenizers-0.13.3 transformers-4.16.2 xxhash-3.2.0 yarl-1.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/DLProject/bias-bench/data/text\n",
        "# !unzip wikipedia-2.5.txt.zip\n",
        "# !unzip wikipedia-10.txt.zip\n",
        "%ls\n",
        "%cd /content/drive/MyDrive/DLProject/bias-bench"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8D-iK0HtX_K",
        "outputId": "4d8c7800-8ba3-4967-b7ae-9818fa922a23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/DLProject/bias-bench/data/text\n",
            "wikipedia-10.txt      wikipedia-2.5.txt\n",
            "wikipedia-10.txt.zip  wikipedia-2.5.txt.zip\n",
            "/content/drive/MyDrive/DLProject/bias-bench\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models\n",
        "- BertForMaskedLM / AutoModelForMaskedLM\n",
        "    - bert-base-uncased\n",
        "        - distilbert-base-uncased\n",
        "        - distilbert-base-uncased-finetuned-sst-2-english\n",
        "    - roberta-base\n",
        "        - distilroberta-base\n",
        "        - sentence-transformers/all-distilroberta-v1\n",
        "    - bert-base-multilingual-cased\n",
        "        - distilbert-base-multilingual-cased\n",
        "        - Davlan/distilbert-base-multilingual-cased-ner-hrl\n",
        "- GPT2LMHeadModel\n",
        "    - gpt2\n",
        "        - distilgpt2"
      ],
      "metadata": {
        "id": "o4uYeGIVaHW4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%ls results/stereoset/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJyJF_pMSL93",
        "outputId": "fb880907-510c-46be-9d5d-5d0b75be0742"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stereoset_m-AutoModelForMaskedLM_c-bert-base-multilingual-cased.json\n",
            "stereoset_m-AutoModelForMaskedLM_c-Davlan-distilbert-base-multilingual-cased-ner-hrl.json\n",
            "stereoset_m-AutoModelForMaskedLM_c-distilbert-base-multilingual-cased.json\n",
            "stereoset_m-AutoModelForMaskedLM_c-distilbert-base-uncased-finetuned-sst-2-english.json\n",
            "stereoset_m-AutoModelForMaskedLM_c-distilbert-base-uncased.json\n",
            "stereoset_m-AutoModelForMaskedLM_c-distilroberta-base.json\n",
            "stereoset_m-AutoModelForMaskedLM_c-roberta-base.json\n",
            "stereoset_m-AutoModelForMaskedLM_c-sentence-transformers-all-distilroberta-v1.json\n",
            "stereoset_m-BertForMaskedLM_c-bert-base-uncased.json\n",
            "stereoset_m-GPT2LMHeadModel_c-distilgpt2.json\n",
            "stereoset_m-GPT2LMHeadModel_c-gpt2.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 experiments/stereoset.py --model AutoModelForMaskedLM --model_name_or_path sentence-transformers/all-distilroberta-v1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drWFHnenht3N",
        "outputId": "4ec87193-a37e-4cd6-e9ec-cce3c4b9d5b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running StereoSet:\n",
            " - persistent_dir: /content/drive/MyDrive/DLProject/bias-bench\n",
            " - model: AutoModelForMaskedLM\n",
            " - model_name_or_path: sentence-transformers/all-distilroberta-v1\n",
            " - batch_size: 1\n",
            " - seed: None\n",
            "Downloading: 100% 653/653 [00:00<00:00, 607kB/s]\n",
            "Downloading: 100% 313M/313M [00:03<00:00, 95.1MB/s]\n",
            "Some weights of RobertaForMaskedLM were not initialized from the model checkpoint at sentence-transformers/all-distilroberta-v1 and are newly initialized: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Downloading: 100% 333/333 [00:00<00:00, 326kB/s]\n",
            "Downloading: 100% 780k/780k [00:00<00:00, 12.0MB/s]\n",
            "Downloading: 100% 446k/446k [00:00<00:00, 2.27MB/s]\n",
            "Downloading: 100% 1.29M/1.29M [00:00<00:00, 6.77MB/s]\n",
            "Downloading: 100% 239/239 [00:00<00:00, 214kB/s]\n",
            "Evaluating intrasentence task.\n",
            "2023-04-28 20:36:30.954285: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-04-28 20:36:31.011522: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-28 20:36:32.059886: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "100% 23941/23941 [03:01<00:00, 131.86it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 experiments/stereoset_evaluation.py --predictions_dir results/stereoset/ --output_file output.txt "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYhDZLY-tSAS",
        "outputId": "3d33ed27-1a27-4e12-ec9e-06cc32744552"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating StereoSet files:\n",
            " - predictions_file: None\n",
            " - predictions_dir: results/stereoset/\n",
            " - output_file: output.txt\n",
            "\n",
            "Evaluating results/stereoset/stereoset_m-BertForMaskedLM_c-bert-base-uncased.json...\n",
            "intrasentence\n",
            "\tgender\n",
            "\t\tCount: 2313.0\n",
            "\t\tLM Score: 85.73970402503635\n",
            "\t\tSS Score: 60.278684896276104\n",
            "\t\tICAT Score: 68.11387600956986\n",
            "\tprofession\n",
            "\t\tCount: 7194.0\n",
            "\t\tLM Score: 83.85202686230224\n",
            "\t\tSS Score: 58.93389453546499\n",
            "\t\tICAT Score: 68.86952357084654\n",
            "\trace\n",
            "\t\tCount: 8928.0\n",
            "\t\tLM Score: 84.00827460718995\n",
            "\t\tSS Score: 57.02967880452161\n",
            "\t\tICAT Score: 72.19725085897807\n",
            "\treligion\n",
            "\t\tCount: 741.0\n",
            "\t\tLM Score: 84.21150995925436\n",
            "\t\tSS Score: 59.70419362150916\n",
            "\t\tICAT Score: 67.86741400316933\n",
            "\toverall\n",
            "\t\tCount: 6392.0\n",
            "\t\tLM Score: 84.17236429175225\n",
            "\t\tSS Score: 58.24009298588702\n",
            "\t\tICAT Score: 70.30060211963236\n",
            "overall\n",
            "\tCount: 6392.0\n",
            "\tLM Score: 84.17236429175225\n",
            "\tSS Score: 58.24009298588702\n",
            "\tICAT Score: 70.30060211963236\n",
            "\n",
            "Evaluating results/stereoset/stereoset_m-AutoModelForMaskedLM_c-distilroberta-base.json...\n",
            "intrasentence\n",
            "\tgender\n",
            "\t\tCount: 2313.0\n",
            "\t\tLM Score: 89.97755428396357\n",
            "\t\tSS Score: 64.28065642503424\n",
            "\t\tICAT Score: 64.27878351008054\n",
            "\tprofession\n",
            "\t\tCount: 7194.0\n",
            "\t\tLM Score: 87.39482034441491\n",
            "\t\tSS Score: 60.866511436198905\n",
            "\t\tICAT Score: 68.40128404967224\n",
            "\trace\n",
            "\t\tCount: 8928.0\n",
            "\t\tLM Score: 90.4336156913391\n",
            "\t\tSS Score: 61.27142218980143\n",
            "\t\tICAT Score: 70.04730643919241\n",
            "\treligion\n",
            "\t\tCount: 741.0\n",
            "\t\tLM Score: 89.08718863452518\n",
            "\t\tSS Score: 65.43523914986034\n",
            "\t\tICAT Score: 61.58554739927286\n",
            "\toverall\n",
            "\t\tCount: 6392.0\n",
            "\t\tLM Score: 89.1968749187946\n",
            "\t\tSS Score: 61.648733809112535\n",
            "\t\tICAT Score: 68.41626186811972\n",
            "overall\n",
            "\tCount: 6392.0\n",
            "\tLM Score: 89.1968749187946\n",
            "\tSS Score: 61.648733809112535\n",
            "\tICAT Score: 68.41626186811972\n",
            "\n",
            "Evaluating results/stereoset/stereoset_m-AutoModelForMaskedLM_c-roberta-base.json...\n",
            "intrasentence\n",
            "\tgender\n",
            "\t\tCount: 2313.0\n",
            "\t\tLM Score: 89.79372775548435\n",
            "\t\tSS Score: 66.32296319557689\n",
            "\t\tICAT Score: 60.479733488555915\n",
            "\tprofession\n",
            "\t\tCount: 7194.0\n",
            "\t\tLM Score: 87.47715350279888\n",
            "\t\tSS Score: 61.46692360958856\n",
            "\t\tICAT Score: 67.41527676678193\n",
            "\trace\n",
            "\t\tCount: 8928.0\n",
            "\t\tLM Score: 89.92745575387676\n",
            "\t\tSS Score: 61.674303732750964\n",
            "\t\tICAT Score: 68.93064710619115\n",
            "\treligion\n",
            "\t\tCount: 741.0\n",
            "\t\tLM Score: 88.03081934338886\n",
            "\t\tSS Score: 64.2778194811318\n",
            "\t\tICAT Score: 62.89305639616823\n",
            "\toverall\n",
            "\t\tCount: 6392.0\n",
            "\t\tLM Score: 88.92907240576449\n",
            "\t\tSS Score: 62.27028395810464\n",
            "\t\tICAT Score: 67.10537299477292\n",
            "overall\n",
            "\tCount: 6392.0\n",
            "\tLM Score: 88.92907240576449\n",
            "\tSS Score: 62.27028395810464\n",
            "\tICAT Score: 67.10537299477292\n",
            "\n",
            "Evaluating results/stereoset/stereoset_m-AutoModelForMaskedLM_c-distilbert-base-uncased.json...\n",
            "intrasentence\n",
            "\tgender\n",
            "\t\tCount: 2313.0\n",
            "\t\tLM Score: 84.80179075695068\n",
            "\t\tSS Score: 60.63435230991453\n",
            "\t\tICAT Score: 66.76554836852932\n",
            "\tprofession\n",
            "\t\tCount: 7194.0\n",
            "\t\tLM Score: 85.35162840522888\n",
            "\t\tSS Score: 58.8829064774944\n",
            "\t\tICAT Score: 70.18821774871883\n",
            "\trace\n",
            "\t\tCount: 8928.0\n",
            "\t\tLM Score: 85.02232491720856\n",
            "\t\tSS Score: 58.70546874538934\n",
            "\t\tICAT Score: 70.21914107266663\n",
            "\treligion\n",
            "\t\tCount: 741.0\n",
            "\t\tLM Score: 84.34262212379875\n",
            "\t\tSS Score: 62.482362275342126\n",
            "\t\tICAT Score: 63.28671883176792\n",
            "\toverall\n",
            "\t\tCount: 6392.0\n",
            "\t\tLM Score: 85.09217600800777\n",
            "\t\tSS Score: 59.15103876437606\n",
            "\t\tICAT Score: 69.51853998411997\n",
            "overall\n",
            "\tCount: 6392.0\n",
            "\tLM Score: 85.09217600800777\n",
            "\tSS Score: 59.15103876437606\n",
            "\tICAT Score: 69.51853998411997\n",
            "\n",
            "Evaluating results/stereoset/stereoset_m-GPT2LMHeadModel_c-distilgpt2.json...\n",
            "intrasentence\n",
            "\tgender\n",
            "\t\tCount: 2313.0\n",
            "\t\tLM Score: 89.63660187055987\n",
            "\t\tSS Score: 61.899273985680786\n",
            "\t\tICAT Score: 68.3043921744963\n",
            "\tprofession\n",
            "\t\tCount: 7194.0\n",
            "\t\tLM Score: 89.00167338729025\n",
            "\t\tSS Score: 59.55048523875508\n",
            "\t\tICAT Score: 72.00149002909393\n",
            "\trace\n",
            "\t\tCount: 8928.0\n",
            "\t\tLM Score: 89.3279062252737\n",
            "\t\tSS Score: 57.46082447897898\n",
            "\t\tICAT Score: 75.99870963684448\n",
            "\treligion\n",
            "\t\tCount: 741.0\n",
            "\t\tLM Score: 87.19459798590933\n",
            "\t\tSS Score: 61.12425078869276\n",
            "\t\tICAT Score: 67.79510647761933\n",
            "\toverall\n",
            "\t\tCount: 6392.0\n",
            "\t\tLM Score: 89.16551010868608\n",
            "\t\tSS Score: 58.92443518298033\n",
            "\t\tICAT Score: 73.25047379823914\n",
            "overall\n",
            "\tCount: 6392.0\n",
            "\tLM Score: 89.16551010868608\n",
            "\tSS Score: 58.92443518298033\n",
            "\tICAT Score: 73.25047379823914\n",
            "\n",
            "Evaluating results/stereoset/stereoset_m-AutoModelForMaskedLM_c-bert-base-multilingual-cased.json...\n",
            "intrasentence\n",
            "\tgender\n",
            "\t\tCount: 2313.0\n",
            "\t\tLM Score: 71.23907682263506\n",
            "\t\tSS Score: 54.308686368881276\n",
            "\t\tICAT Score: 65.10014003788758\n",
            "\tprofession\n",
            "\t\tCount: 7194.0\n",
            "\t\tLM Score: 68.5914091357531\n",
            "\t\tSS Score: 49.69109680845237\n",
            "\t\tICAT Score: 68.16764703185743\n",
            "\trace\n",
            "\t\tCount: 8928.0\n",
            "\t\tLM Score: 70.04739452938844\n",
            "\t\tSS Score: 56.68868248908724\n",
            "\t\tICAT Score: 60.67689890549032\n",
            "\treligion\n",
            "\t\tCount: 741.0\n",
            "\t\tLM Score: 76.7312740199281\n",
            "\t\tSS Score: 50.13056300598013\n",
            "\t\tICAT Score: 76.53090870415356\n",
            "\toverall\n",
            "\t\tCount: 6392.0\n",
            "\t\tLM Score: 69.90221559874826\n",
            "\t\tSS Score: 53.54733674441252\n",
            "\t\tICAT Score: 64.94288164056255\n",
            "overall\n",
            "\tCount: 6392.0\n",
            "\tLM Score: 69.90221559874826\n",
            "\tSS Score: 53.54733674441252\n",
            "\tICAT Score: 64.94288164056255\n",
            "\n",
            "Evaluating results/stereoset/stereoset_m-AutoModelForMaskedLM_c-distilbert-base-multilingual-cased.json...\n",
            "intrasentence\n",
            "\tgender\n",
            "\t\tCount: 2313.0\n",
            "\t\tLM Score: 73.32401214755039\n",
            "\t\tSS Score: 51.46777008228783\n",
            "\t\tICAT Score: 71.17155632068072\n",
            "\tprofession\n",
            "\t\tCount: 7194.0\n",
            "\t\tLM Score: 70.92966473984998\n",
            "\t\tSS Score: 50.08993742757372\n",
            "\t\tICAT Score: 70.8020801081426\n",
            "\trace\n",
            "\t\tCount: 8928.0\n",
            "\t\tLM Score: 73.76810072184502\n",
            "\t\tSS Score: 56.80091776013091\n",
            "\t\tICAT Score: 63.73428499523859\n",
            "\treligion\n",
            "\t\tCount: 741.0\n",
            "\t\tLM Score: 80.72431220527871\n",
            "\t\tSS Score: 49.68964738461711\n",
            "\t\tICAT Score: 80.22325217692084\n",
            "\toverall\n",
            "\t\tCount: 6392.0\n",
            "\t\tLM Score: 72.9161338116901\n",
            "\t\tSS Score: 53.37949588556453\n",
            "\t\tICAT Score: 67.98773832753251\n",
            "overall\n",
            "\tCount: 6392.0\n",
            "\tLM Score: 72.9161338116901\n",
            "\tSS Score: 53.37949588556453\n",
            "\tICAT Score: 67.98773832753251\n",
            "\n",
            "Evaluating results/stereoset/stereoset_m-GPT2LMHeadModel_c-gpt2.json...\n",
            "intrasentence\n",
            "\tgender\n",
            "\t\tCount: 2313.0\n",
            "\t\tLM Score: 92.01218436319637\n",
            "\t\tSS Score: 62.6460866303445\n",
            "\t\tICAT Score: 68.74030327311215\n",
            "\tprofession\n",
            "\t\tCount: 7194.0\n",
            "\t\tLM Score: 90.74056951271717\n",
            "\t\tSS Score: 61.305512436683145\n",
            "\t\tICAT Score: 70.22319676996246\n",
            "\trace\n",
            "\t\tCount: 8928.0\n",
            "\t\tLM Score: 90.9524178709514\n",
            "\t\tSS Score: 58.904167347320374\n",
            "\t\tICAT Score: 74.75530688362413\n",
            "\treligion\n",
            "\t\tCount: 741.0\n",
            "\t\tLM Score: 91.20561944224038\n",
            "\t\tSS Score: 63.260092672402635\n",
            "\t\tICAT Score: 67.01772012128048\n",
            "\toverall\n",
            "\t\tCount: 6392.0\n",
            "\t\tLM Score: 91.01442389024014\n",
            "\t\tSS Score: 60.42310108475473\n",
            "\t\tICAT Score: 72.04137308266637\n",
            "overall\n",
            "\tCount: 6392.0\n",
            "\tLM Score: 91.01442389024014\n",
            "\tSS Score: 60.42310108475473\n",
            "\tICAT Score: 72.04137308266637\n",
            "\n",
            "Evaluating results/stereoset/stereoset_m-AutoModelForMaskedLM_c-Davlan-distilbert-base-multilingual-cased-ner-hrl.json...\n",
            "intrasentence\n",
            "\tgender\n",
            "\t\tCount: 2313.0\n",
            "\t\tLM Score: 63.932183888168396\n",
            "\t\tSS Score: 46.05793467087819\n",
            "\t\tICAT Score: 58.89168697775663\n",
            "\tprofession\n",
            "\t\tCount: 7194.0\n",
            "\t\tLM Score: 61.15532176386198\n",
            "\t\tSS Score: 48.194658579675746\n",
            "\t\tICAT Score: 58.947197054790834\n",
            "\trace\n",
            "\t\tCount: 8928.0\n",
            "\t\tLM Score: 60.62737410515252\n",
            "\t\tSS Score: 41.041742035050625\n",
            "\t\tICAT Score: 49.76506096572356\n",
            "\treligion\n",
            "\t\tCount: 741.0\n",
            "\t\tLM Score: 64.20895395682197\n",
            "\t\tSS Score: 45.56928466828355\n",
            "\t\tICAT Score: 58.51912202222264\n",
            "\toverall\n",
            "\t\tCount: 6392.0\n",
            "\t\tLM Score: 61.36660468961265\n",
            "\t\tSS Score: 44.49213935649767\n",
            "\t\tICAT Score: 54.606630553706985\n",
            "overall\n",
            "\tCount: 6392.0\n",
            "\tLM Score: 61.36660468961265\n",
            "\tSS Score: 44.49213935649767\n",
            "\tICAT Score: 54.606630553706985\n",
            "\n",
            "Evaluating results/stereoset/stereoset_m-AutoModelForMaskedLM_c-distilbert-base-uncased-finetuned-sst-2-english.json...\n",
            "intrasentence\n",
            "\tgender\n",
            "\t\tCount: 2313.0\n",
            "\t\tLM Score: 51.400076920229345\n",
            "\t\tSS Score: 47.83333396294416\n",
            "\t\tICAT Score: 49.17274090092697\n",
            "\tprofession\n",
            "\t\tCount: 7194.0\n",
            "\t\tLM Score: 59.37627911000149\n",
            "\t\tSS Score: 49.5195775269475\n",
            "\t\tICAT Score: 58.805765132987844\n",
            "\trace\n",
            "\t\tCount: 8928.0\n",
            "\t\tLM Score: 55.598075930700006\n",
            "\t\tSS Score: 49.72824929499184\n",
            "\t\tICAT Score: 55.295899604074705\n",
            "\treligion\n",
            "\t\tCount: 741.0\n",
            "\t\tLM Score: 55.40523324480807\n",
            "\t\tSS Score: 50.796355715401575\n",
            "\t\tICAT Score: 54.52278776165487\n",
            "\toverall\n",
            "\t\tCount: 6392.0\n",
            "\t\tLM Score: 56.4756078796669\n",
            "\t\tSS Score: 49.45546019870367\n",
            "\t\tICAT Score: 55.86054355380924\n",
            "overall\n",
            "\tCount: 6392.0\n",
            "\tLM Score: 56.4756078796669\n",
            "\tSS Score: 49.45546019870367\n",
            "\tICAT Score: 55.86054355380924\n",
            "\n",
            "Evaluating results/stereoset/stereoset_m-AutoModelForMaskedLM_c-sentence-transformers-all-distilroberta-v1.json...\n",
            "intrasentence\n",
            "\tgender\n",
            "\t\tCount: 2313.0\n",
            "\t\tLM Score: 52.3965563620861\n",
            "\t\tSS Score: 48.3272215938133\n",
            "\t\tICAT Score: 50.64359980126526\n",
            "\tprofession\n",
            "\t\tCount: 7194.0\n",
            "\t\tLM Score: 48.76063783871452\n",
            "\t\tSS Score: 51.574068736225286\n",
            "\t\tICAT Score: 47.225585927108035\n",
            "\trace\n",
            "\t\tCount: 8928.0\n",
            "\t\tLM Score: 49.15611692916111\n",
            "\t\tSS Score: 52.061189714918086\n",
            "\t\tICAT Score: 47.12971527636715\n",
            "\treligion\n",
            "\t\tCount: 741.0\n",
            "\t\tLM Score: 40.731587850299995\n",
            "\t\tSS Score: 43.382434202481164\n",
            "\t\tICAT Score: 35.340708597564415\n",
            "\toverall\n",
            "\t\tCount: 6392.0\n",
            "\t\tLM Score: 49.097436363614854\n",
            "\t\tSS Score: 51.09437677554855\n",
            "\t\tICAT Score: 48.0228144817086\n",
            "overall\n",
            "\tCount: 6392.0\n",
            "\tLM Score: 49.097436363614854\n",
            "\tSS Score: 51.09437677554855\n",
            "\tICAT Score: 48.0228144817086\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uFSpIkV0E3G8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}