{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language Model</th>\n",
       "      <th>Varient</th>\n",
       "      <th>Category</th>\n",
       "      <th>LM Score</th>\n",
       "      <th>SS Score</th>\n",
       "      <th>ICAT Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BertForMaskedLM</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>Gender</td>\n",
       "      <td>85.74</td>\n",
       "      <td>60.28</td>\n",
       "      <td>68.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BertForMaskedLM</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>Profession</td>\n",
       "      <td>83.85</td>\n",
       "      <td>58.93</td>\n",
       "      <td>68.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BertForMaskedLM</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>Race</td>\n",
       "      <td>84.01</td>\n",
       "      <td>57.03</td>\n",
       "      <td>72.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BertForMaskedLM</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>Religion</td>\n",
       "      <td>84.21</td>\n",
       "      <td>59.70</td>\n",
       "      <td>67.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AutoModelForMaskedLM</td>\n",
       "      <td>distilroberta-base</td>\n",
       "      <td>Gender</td>\n",
       "      <td>89.98</td>\n",
       "      <td>64.28</td>\n",
       "      <td>64.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Language Model             Varient    Category  LM Score  SS Score   \n",
       "0       BertForMaskedLM   bert-base-uncased      Gender     85.74     60.28  \\\n",
       "1       BertForMaskedLM   bert-base-uncased  Profession     83.85     58.93   \n",
       "2       BertForMaskedLM   bert-base-uncased        Race     84.01     57.03   \n",
       "3       BertForMaskedLM   bert-base-uncased    Religion     84.21     59.70   \n",
       "4  AutoModelForMaskedLM  distilroberta-base      Gender     89.98     64.28   \n",
       "\n",
       "   ICAT Score  \n",
       "0       68.11  \n",
       "1       68.87  \n",
       "2       72.20  \n",
       "3       67.87  \n",
       "4       64.28  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "path = \"/Users/shanglinghsu/Downloads/output.txt\"\n",
    "output = json.load(open(path))\n",
    "entries = []\n",
    "for model_string, result in output.items():\n",
    "    lm = model_string.split(\"_\")[1][2:]\n",
    "    varient = model_string.split(\"_\")[2][2:]\n",
    "    for cat, scores in result[\"intrasentence\"].items():\n",
    "        if cat == \"overall\": continue\n",
    "        cat = cat[0].upper() + cat[1:]\n",
    "        entry = {\n",
    "            \"Language Model\": lm,\n",
    "            \"Varient\": varient,\n",
    "            \"Category\": cat,\n",
    "            \"LM Score\": round(scores[\"LM Score\"], 2),\n",
    "            \"SS Score\": round(scores[\"SS Score\"], 2),\n",
    "            \"ICAT Score\": round(scores[\"ICAT Score\"], 2),\n",
    "        }\n",
    "        entries.append(entry)\n",
    "\n",
    "df = pd.DataFrame(entries)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language Model</th>\n",
       "      <th>Varient</th>\n",
       "      <th>Category</th>\n",
       "      <th>LM Score</th>\n",
       "      <th>SS Score</th>\n",
       "      <th>ICAT Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BertForMaskedLM</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>Gender</td>\n",
       "      <td>85.74</td>\n",
       "      <td>60.28</td>\n",
       "      <td>68.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BertForMaskedLM</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>Profession</td>\n",
       "      <td>83.85</td>\n",
       "      <td>58.93</td>\n",
       "      <td>68.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BertForMaskedLM</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>Race</td>\n",
       "      <td>84.01</td>\n",
       "      <td>57.03</td>\n",
       "      <td>72.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BertForMaskedLM</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>Religion</td>\n",
       "      <td>84.21</td>\n",
       "      <td>59.70</td>\n",
       "      <td>67.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AutoModelForMaskedLM</td>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>Gender</td>\n",
       "      <td>84.80</td>\n",
       "      <td>60.63</td>\n",
       "      <td>66.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AutoModelForMaskedLM</td>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>Profession</td>\n",
       "      <td>85.35</td>\n",
       "      <td>58.88</td>\n",
       "      <td>70.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AutoModelForMaskedLM</td>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>Race</td>\n",
       "      <td>85.02</td>\n",
       "      <td>58.71</td>\n",
       "      <td>70.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AutoModelForMaskedLM</td>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>Religion</td>\n",
       "      <td>84.34</td>\n",
       "      <td>62.48</td>\n",
       "      <td>63.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>AutoModelForMaskedLM</td>\n",
       "      <td>distilbert-base-uncased-finetuned-sst-2-english</td>\n",
       "      <td>Gender</td>\n",
       "      <td>51.40</td>\n",
       "      <td>47.83</td>\n",
       "      <td>49.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>AutoModelForMaskedLM</td>\n",
       "      <td>distilbert-base-uncased-finetuned-sst-2-english</td>\n",
       "      <td>Profession</td>\n",
       "      <td>59.38</td>\n",
       "      <td>49.52</td>\n",
       "      <td>58.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>AutoModelForMaskedLM</td>\n",
       "      <td>distilbert-base-uncased-finetuned-sst-2-english</td>\n",
       "      <td>Race</td>\n",
       "      <td>55.60</td>\n",
       "      <td>49.73</td>\n",
       "      <td>55.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>AutoModelForMaskedLM</td>\n",
       "      <td>distilbert-base-uncased-finetuned-sst-2-english</td>\n",
       "      <td>Religion</td>\n",
       "      <td>55.41</td>\n",
       "      <td>50.80</td>\n",
       "      <td>54.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>AutoModelForMaskedLM</td>\n",
       "      <td>bert-base-multilingual-cased</td>\n",
       "      <td>Gender</td>\n",
       "      <td>71.24</td>\n",
       "      <td>54.31</td>\n",
       "      <td>65.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>AutoModelForMaskedLM</td>\n",
       "      <td>bert-base-multilingual-cased</td>\n",
       "      <td>Profession</td>\n",
       "      <td>68.59</td>\n",
       "      <td>49.69</td>\n",
       "      <td>68.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>AutoModelForMaskedLM</td>\n",
       "      <td>bert-base-multilingual-cased</td>\n",
       "      <td>Race</td>\n",
       "      <td>70.05</td>\n",
       "      <td>56.69</td>\n",
       "      <td>60.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>AutoModelForMaskedLM</td>\n",
       "      <td>bert-base-multilingual-cased</td>\n",
       "      <td>Religion</td>\n",
       "      <td>76.73</td>\n",
       "      <td>50.13</td>\n",
       "      <td>76.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>AutoModelForMaskedLM</td>\n",
       "      <td>distilbert-base-multilingual-cased</td>\n",
       "      <td>Gender</td>\n",
       "      <td>73.32</td>\n",
       "      <td>51.47</td>\n",
       "      <td>71.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>AutoModelForMaskedLM</td>\n",
       "      <td>distilbert-base-multilingual-cased</td>\n",
       "      <td>Profession</td>\n",
       "      <td>70.93</td>\n",
       "      <td>50.09</td>\n",
       "      <td>70.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>AutoModelForMaskedLM</td>\n",
       "      <td>distilbert-base-multilingual-cased</td>\n",
       "      <td>Race</td>\n",
       "      <td>73.77</td>\n",
       "      <td>56.80</td>\n",
       "      <td>63.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>AutoModelForMaskedLM</td>\n",
       "      <td>distilbert-base-multilingual-cased</td>\n",
       "      <td>Religion</td>\n",
       "      <td>80.72</td>\n",
       "      <td>49.69</td>\n",
       "      <td>80.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>AutoModelForMaskedLM</td>\n",
       "      <td>Davlan-distilbert-base-multilingual-cased-ner-hrl</td>\n",
       "      <td>Gender</td>\n",
       "      <td>63.93</td>\n",
       "      <td>46.06</td>\n",
       "      <td>58.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>AutoModelForMaskedLM</td>\n",
       "      <td>Davlan-distilbert-base-multilingual-cased-ner-hrl</td>\n",
       "      <td>Profession</td>\n",
       "      <td>61.16</td>\n",
       "      <td>48.19</td>\n",
       "      <td>58.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>AutoModelForMaskedLM</td>\n",
       "      <td>Davlan-distilbert-base-multilingual-cased-ner-hrl</td>\n",
       "      <td>Race</td>\n",
       "      <td>60.63</td>\n",
       "      <td>41.04</td>\n",
       "      <td>49.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>AutoModelForMaskedLM</td>\n",
       "      <td>Davlan-distilbert-base-multilingual-cased-ner-hrl</td>\n",
       "      <td>Religion</td>\n",
       "      <td>64.21</td>\n",
       "      <td>45.57</td>\n",
       "      <td>58.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AutoModelForMaskedLM</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>Gender</td>\n",
       "      <td>89.79</td>\n",
       "      <td>66.32</td>\n",
       "      <td>60.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AutoModelForMaskedLM</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>Profession</td>\n",
       "      <td>87.48</td>\n",
       "      <td>61.47</td>\n",
       "      <td>67.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AutoModelForMaskedLM</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>Race</td>\n",
       "      <td>89.93</td>\n",
       "      <td>61.67</td>\n",
       "      <td>68.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AutoModelForMaskedLM</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>Religion</td>\n",
       "      <td>88.03</td>\n",
       "      <td>64.28</td>\n",
       "      <td>62.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AutoModelForMaskedLM</td>\n",
       "      <td>distilroberta-base</td>\n",
       "      <td>Gender</td>\n",
       "      <td>89.98</td>\n",
       "      <td>64.28</td>\n",
       "      <td>64.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AutoModelForMaskedLM</td>\n",
       "      <td>distilroberta-base</td>\n",
       "      <td>Profession</td>\n",
       "      <td>87.39</td>\n",
       "      <td>60.87</td>\n",
       "      <td>68.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AutoModelForMaskedLM</td>\n",
       "      <td>distilroberta-base</td>\n",
       "      <td>Race</td>\n",
       "      <td>90.43</td>\n",
       "      <td>61.27</td>\n",
       "      <td>70.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AutoModelForMaskedLM</td>\n",
       "      <td>distilroberta-base</td>\n",
       "      <td>Religion</td>\n",
       "      <td>89.09</td>\n",
       "      <td>65.44</td>\n",
       "      <td>61.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>AutoModelForMaskedLM</td>\n",
       "      <td>sentence-transformers-all-distilroberta-v1</td>\n",
       "      <td>Gender</td>\n",
       "      <td>52.40</td>\n",
       "      <td>48.33</td>\n",
       "      <td>50.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>AutoModelForMaskedLM</td>\n",
       "      <td>sentence-transformers-all-distilroberta-v1</td>\n",
       "      <td>Profession</td>\n",
       "      <td>48.76</td>\n",
       "      <td>51.57</td>\n",
       "      <td>47.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>AutoModelForMaskedLM</td>\n",
       "      <td>sentence-transformers-all-distilroberta-v1</td>\n",
       "      <td>Race</td>\n",
       "      <td>49.16</td>\n",
       "      <td>52.06</td>\n",
       "      <td>47.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>AutoModelForMaskedLM</td>\n",
       "      <td>sentence-transformers-all-distilroberta-v1</td>\n",
       "      <td>Religion</td>\n",
       "      <td>40.73</td>\n",
       "      <td>43.38</td>\n",
       "      <td>35.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>GPT2LMHeadModel</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>Gender</td>\n",
       "      <td>92.01</td>\n",
       "      <td>62.65</td>\n",
       "      <td>68.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>GPT2LMHeadModel</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>Profession</td>\n",
       "      <td>90.74</td>\n",
       "      <td>61.31</td>\n",
       "      <td>70.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>GPT2LMHeadModel</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>Race</td>\n",
       "      <td>90.95</td>\n",
       "      <td>58.90</td>\n",
       "      <td>74.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>GPT2LMHeadModel</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>Religion</td>\n",
       "      <td>91.21</td>\n",
       "      <td>63.26</td>\n",
       "      <td>67.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>GPT2LMHeadModel</td>\n",
       "      <td>distilgpt2</td>\n",
       "      <td>Gender</td>\n",
       "      <td>89.64</td>\n",
       "      <td>61.90</td>\n",
       "      <td>68.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>GPT2LMHeadModel</td>\n",
       "      <td>distilgpt2</td>\n",
       "      <td>Profession</td>\n",
       "      <td>89.00</td>\n",
       "      <td>59.55</td>\n",
       "      <td>72.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>GPT2LMHeadModel</td>\n",
       "      <td>distilgpt2</td>\n",
       "      <td>Race</td>\n",
       "      <td>89.33</td>\n",
       "      <td>57.46</td>\n",
       "      <td>76.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>GPT2LMHeadModel</td>\n",
       "      <td>distilgpt2</td>\n",
       "      <td>Religion</td>\n",
       "      <td>87.19</td>\n",
       "      <td>61.12</td>\n",
       "      <td>67.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Language Model                                            Varient   \n",
       "0        BertForMaskedLM                                  bert-base-uncased  \\\n",
       "1        BertForMaskedLM                                  bert-base-uncased   \n",
       "2        BertForMaskedLM                                  bert-base-uncased   \n",
       "3        BertForMaskedLM                                  bert-base-uncased   \n",
       "12  AutoModelForMaskedLM                            distilbert-base-uncased   \n",
       "13  AutoModelForMaskedLM                            distilbert-base-uncased   \n",
       "14  AutoModelForMaskedLM                            distilbert-base-uncased   \n",
       "15  AutoModelForMaskedLM                            distilbert-base-uncased   \n",
       "36  AutoModelForMaskedLM    distilbert-base-uncased-finetuned-sst-2-english   \n",
       "37  AutoModelForMaskedLM    distilbert-base-uncased-finetuned-sst-2-english   \n",
       "38  AutoModelForMaskedLM    distilbert-base-uncased-finetuned-sst-2-english   \n",
       "39  AutoModelForMaskedLM    distilbert-base-uncased-finetuned-sst-2-english   \n",
       "20  AutoModelForMaskedLM                       bert-base-multilingual-cased   \n",
       "21  AutoModelForMaskedLM                       bert-base-multilingual-cased   \n",
       "22  AutoModelForMaskedLM                       bert-base-multilingual-cased   \n",
       "23  AutoModelForMaskedLM                       bert-base-multilingual-cased   \n",
       "24  AutoModelForMaskedLM                 distilbert-base-multilingual-cased   \n",
       "25  AutoModelForMaskedLM                 distilbert-base-multilingual-cased   \n",
       "26  AutoModelForMaskedLM                 distilbert-base-multilingual-cased   \n",
       "27  AutoModelForMaskedLM                 distilbert-base-multilingual-cased   \n",
       "32  AutoModelForMaskedLM  Davlan-distilbert-base-multilingual-cased-ner-hrl   \n",
       "33  AutoModelForMaskedLM  Davlan-distilbert-base-multilingual-cased-ner-hrl   \n",
       "34  AutoModelForMaskedLM  Davlan-distilbert-base-multilingual-cased-ner-hrl   \n",
       "35  AutoModelForMaskedLM  Davlan-distilbert-base-multilingual-cased-ner-hrl   \n",
       "8   AutoModelForMaskedLM                                       roberta-base   \n",
       "9   AutoModelForMaskedLM                                       roberta-base   \n",
       "10  AutoModelForMaskedLM                                       roberta-base   \n",
       "11  AutoModelForMaskedLM                                       roberta-base   \n",
       "4   AutoModelForMaskedLM                                 distilroberta-base   \n",
       "5   AutoModelForMaskedLM                                 distilroberta-base   \n",
       "6   AutoModelForMaskedLM                                 distilroberta-base   \n",
       "7   AutoModelForMaskedLM                                 distilroberta-base   \n",
       "40  AutoModelForMaskedLM         sentence-transformers-all-distilroberta-v1   \n",
       "41  AutoModelForMaskedLM         sentence-transformers-all-distilroberta-v1   \n",
       "42  AutoModelForMaskedLM         sentence-transformers-all-distilroberta-v1   \n",
       "43  AutoModelForMaskedLM         sentence-transformers-all-distilroberta-v1   \n",
       "28       GPT2LMHeadModel                                               gpt2   \n",
       "29       GPT2LMHeadModel                                               gpt2   \n",
       "30       GPT2LMHeadModel                                               gpt2   \n",
       "31       GPT2LMHeadModel                                               gpt2   \n",
       "16       GPT2LMHeadModel                                         distilgpt2   \n",
       "17       GPT2LMHeadModel                                         distilgpt2   \n",
       "18       GPT2LMHeadModel                                         distilgpt2   \n",
       "19       GPT2LMHeadModel                                         distilgpt2   \n",
       "\n",
       "      Category  LM Score  SS Score  ICAT Score  \n",
       "0       Gender     85.74     60.28       68.11  \n",
       "1   Profession     83.85     58.93       68.87  \n",
       "2         Race     84.01     57.03       72.20  \n",
       "3     Religion     84.21     59.70       67.87  \n",
       "12      Gender     84.80     60.63       66.77  \n",
       "13  Profession     85.35     58.88       70.19  \n",
       "14        Race     85.02     58.71       70.22  \n",
       "15    Religion     84.34     62.48       63.29  \n",
       "36      Gender     51.40     47.83       49.17  \n",
       "37  Profession     59.38     49.52       58.81  \n",
       "38        Race     55.60     49.73       55.30  \n",
       "39    Religion     55.41     50.80       54.52  \n",
       "20      Gender     71.24     54.31       65.10  \n",
       "21  Profession     68.59     49.69       68.17  \n",
       "22        Race     70.05     56.69       60.68  \n",
       "23    Religion     76.73     50.13       76.53  \n",
       "24      Gender     73.32     51.47       71.17  \n",
       "25  Profession     70.93     50.09       70.80  \n",
       "26        Race     73.77     56.80       63.73  \n",
       "27    Religion     80.72     49.69       80.22  \n",
       "32      Gender     63.93     46.06       58.89  \n",
       "33  Profession     61.16     48.19       58.95  \n",
       "34        Race     60.63     41.04       49.77  \n",
       "35    Religion     64.21     45.57       58.52  \n",
       "8       Gender     89.79     66.32       60.48  \n",
       "9   Profession     87.48     61.47       67.42  \n",
       "10        Race     89.93     61.67       68.93  \n",
       "11    Religion     88.03     64.28       62.89  \n",
       "4       Gender     89.98     64.28       64.28  \n",
       "5   Profession     87.39     60.87       68.40  \n",
       "6         Race     90.43     61.27       70.05  \n",
       "7     Religion     89.09     65.44       61.59  \n",
       "40      Gender     52.40     48.33       50.64  \n",
       "41  Profession     48.76     51.57       47.23  \n",
       "42        Race     49.16     52.06       47.13  \n",
       "43    Religion     40.73     43.38       35.34  \n",
       "28      Gender     92.01     62.65       68.74  \n",
       "29  Profession     90.74     61.31       70.22  \n",
       "30        Race     90.95     58.90       74.76  \n",
       "31    Religion     91.21     63.26       67.02  \n",
       "16      Gender     89.64     61.90       68.30  \n",
       "17  Profession     89.00     59.55       72.00  \n",
       "18        Race     89.33     57.46       76.00  \n",
       "19    Religion     87.19     61.12       67.80  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_order = \"\"\"bert-base-uncased\n",
    "distilbert-base-uncased\n",
    "distilbert-base-uncased-finetuned-sst-2-english\n",
    "bert-base-multilingual-cased\n",
    "distilbert-base-multilingual-cased\n",
    "Davlan/distilbert-base-multilingual-cased-ner-hrl\n",
    "roberta-base\n",
    "distilroberta-base\n",
    "sentence-transformers/all-distilroberta-v1\n",
    "gpt2\n",
    "distilgpt2\"\"\".split(\"\\n\")\n",
    "cat_order = [\"Gender\", \"Profession\", \"Race\", \"Religion\"]\n",
    "\n",
    "var_order = {x.replace(\"/\", \"-\"): i for i, x in enumerate(var_order)}\n",
    "cat_order = {x: i for i, x in enumerate(cat_order)}\n",
    "\n",
    "df[\"cat_order\"] = df[\"Category\"].apply(lambda x: cat_order[x])\n",
    "df[\"var_order\"] = df[\"Varient\"].apply(lambda x: var_order[x])\n",
    "\n",
    "df = df.sort_values(by=[\"var_order\", \"cat_order\"])\n",
    "df = df[[c for c in df.columns if \"order\" not in c]]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(path.replace(\"txt\", \"csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
